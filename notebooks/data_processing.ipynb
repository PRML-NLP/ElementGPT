{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import jsonlines\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "data_list = [\n",
    "    \"KoAlpaca/KoAlpaca_v1.1.jsonl\",\n",
    "    \"KoChatGPT/kochatgpt_1_SFT.jsonl\",\n",
    "    \"korquad-chat-v1/korquad-chat.json\",\n",
    "    \"OIG-small-chip2-ko/oig-smallchip2-dedu.jsonl\",\n",
    "    \"ShareGPT_DeepL/ko_alpaca_style_dataset.json\",\n",
    "    \"kullm_v2/kullm-v2.jsonl\",\n",
    "    \"KoAlpaca/ko_alpaca_data.json\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KoAlpaca v1.0 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49620"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_list[-1]\n",
    "\n",
    "with open(os.path.join(DATA_DIR, data_path), \"r\") as f:\n",
    "    koalpaca_v1_0 = json.load(f)\n",
    "\n",
    "len(koalpaca_v1_0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KoAlpaca v1.1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21155"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_list[0]\n",
    "\n",
    "koalpaca_v1_1 = []\n",
    "with jsonlines.open(os.path.join(DATA_DIR, data_path), \"r\") as f:\n",
    "    for line in f.iter():\n",
    "        koalpaca_v1_1.append(line)\n",
    "\n",
    "len(koalpaca_v1_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KochatGPT SFT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_list[1]\n",
    "with open(os.path.join(DATA_DIR, data_path), \"r\") as f:\n",
    "    kochatgpt = json.load(f)\n",
    "\n",
    "len(kochatgpt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korquad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9619"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_list[2]\n",
    "\n",
    "korquad = []\n",
    "with jsonlines.open(os.path.join(DATA_DIR, data_path), \"r\") as f:\n",
    "    for line in f.iter():\n",
    "        korquad.append(line)\n",
    "\n",
    "len(korquad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OIG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210282"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_list[3]\n",
    "\n",
    "oig = []\n",
    "with jsonlines.open(os.path.join(DATA_DIR, data_path), \"r\") as f:\n",
    "    for line in f.iter():\n",
    "        oig.append(line)\n",
    "\n",
    "len(oig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KULLM-v2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152630"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_list[5]\n",
    "\n",
    "kullm = []\n",
    "with jsonlines.open(os.path.join(DATA_DIR, data_path), \"r\") as f:\n",
    "    for line in f.iter():\n",
    "        kullm.append(line)\n",
    "\n",
    "len(kullm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-th Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '6학년 과학 문제:\\n\\n꽃의 구조와 기능은 무엇일까요?', 'output': '꽃은 꽃받침, 꽃잎, 수술, 암술로 이루어져 있습니다. 꽃의 구조는 이 네 부분으로 구성되어 있습니다.'}\n",
      "{'instruction': '달 퍼즐에 대한 6학년 과학 문제 2개 만들어줘', 'output': '문제 1: 왜 달 퍼즐을 맞추는 활동을 하는 건가요?\\n답변: 달 퍼즐 맞추기 활동을 통해 여러 가지 달의 모양에 대한 흥미와 호기심을 가질 수 있습니다.\\n\\n문제 2: 둥근 보름달 이외에 다른 모양의 달을 본 적이 있나요?\\n답변: 여러 가지 모양의 달 퍼즐을 맞추어 보는 놀이를 통해 둥근 보름달 이외에도 다양한 모양의 달을 볼 수 있습니다.'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"../data/6th_grade_QA_과학_filtered.json\", \"r\") as fin:\n",
    "    six_sci_qa = json.load(fin)\n",
    "\n",
    "keywords = []\n",
    "for sample in six_sci_qa:\n",
    "    keywords.append(sample[\"keywords\"].split(\",\")[0])\n",
    "\n",
    "most_keywords = Counter(keywords).most_common(32)\n",
    "\n",
    "sci_six_res = []\n",
    "key_qa_map = {}\n",
    "for sample in six_sci_qa:\n",
    "    for keyword, _ in most_keywords:\n",
    "        if keyword in sample[\"keywords\"]:\n",
    "            if keyword not in key_qa_map:\n",
    "                key_qa_map[keyword] = [sample]\n",
    "            else:\n",
    "                key_qa_map[keyword].append(sample)\n",
    "            break\n",
    "        else:\n",
    "            inst = f\"6학년 과학 문제:\\n\\n{sample['question']}\"\n",
    "            res = sample['answer']\n",
    "            sci_six_res.append({\"instruction\": inst, \"output\": res})\n",
    "\n",
    "inst_form = \"{}에 대한 6학년 과학 주관식 문제 {}개 만들어줘\"\n",
    "\n",
    "sci_six_gen = []\n",
    "for key, qas in key_qa_map.items():\n",
    "    index = 0\n",
    "    while len(qas) > index:      \n",
    "        problems = []\n",
    "        cur_len = 0\n",
    "        choice = random.randint(1,3)\n",
    "        for k, s in enumerate(qas[index:index+choice]):\n",
    "            Q, A = s[\"question\"], s[\"answer\"]\n",
    "            problem = f\"문제 {k+1}: {Q}\\n답변: {A}\"\n",
    "            cur_len += len(problem)\n",
    "            problems.append(problem)\n",
    "            if cur_len > 500:\n",
    "                choice = k+1\n",
    "                break\n",
    "        \n",
    "        inst = inst_form.format(key, choice)\n",
    "        index += choice\n",
    "        sci_six_gen.append({\"instruction\": inst, \"output\": \"\\n\\n\".join(problems)})\n",
    "\n",
    "print(sci_six_res[0])\n",
    "print(sci_six_gen[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878 5913\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "with open(\"../data/gsm8k_ko_main.json\", \"r\") as fin:\n",
    "    gsm8k = json.load(fin)\n",
    "\n",
    "num_problem_gen = int(len(gsm8k) * 0.2)\n",
    "random.shuffle(gsm8k)\n",
    "gen_samples = gsm8k[:num_problem_gen]\n",
    "gsm8k = gsm8k[num_problem_gen:]\n",
    "inst = \"사칙연산을 연습할 수 있도록 다단계 추론이 필요한 수학 주관식 문제 {}개 만들어줘. 그에 대한 해설과 정답도 같이 작성해줘.\"\n",
    "gsm8k_gen = []\n",
    "index = 0\n",
    "while num_problem_gen > index:\n",
    "    choice = random.randint(1,3)\n",
    "    cur_len = 0\n",
    "    problems = []\n",
    "    for k, s in enumerate(gen_samples[index:index+choice]):\n",
    "        Q, A = s[\"question\"], s[\"answer\"]\n",
    "        problem = f\"문제 {k+1}: {Q}\\n해설: {A}\"\n",
    "        cur_len += len(problem)\n",
    "        problems.append(problem)\n",
    "        if cur_len > 500:\n",
    "            choice = k+1\n",
    "            break\n",
    "        \n",
    "    inst = inst.format(choice)\n",
    "    index += choice\n",
    "    gsm8k_gen.append({\"instruction\": inst, \"output\": \"\\n\\n\".join(problems)})\n",
    "\n",
    "gsm8k_solve = []\n",
    "for sample in gsm8k:\n",
    "    gsm8k_solve.append({\n",
    "        \"instruction\": sample[\"question\"],\n",
    "        \"output\": sample[\"answer\"]\n",
    "    })\n",
    "        \n",
    "print(len(gsm8k_gen), len(gsm8k_solve))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAVERPEDIA_수업자료 생성 scenario\n",
    "\n",
    "우리아이 성장백과 -> 영양 과목 \\\n",
    "어린이백과_사회, 어린이백과_한국사, 어린이백과_세계탐구, 어린이백과_유적/유물 탐구 -> 사회 과목 \\\n",
    "어린이백과_과학, 어린이백과_과학탐구 -> 과학 과목 \\\n",
    "어린이백과_세계사 -> 세계사 과목 \\\n",
    "어린이백과_수학 -> 수학 과목 \\\n",
    "어린이백과_소프트웨어 -> 컴퓨터 과목\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영양, 사회, 세계사, 수학, 과학, 컴퓨터\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "naverpedia_class_path = \"../data/web_crawled/naverpedia_class.json\"\n",
    "#format for 성장백과, 사회, 한국사, 세계사, 수학, 과학 \n",
    "ins_format = \"{category} 내 {title}을 주제로 수업 자료를 작성해줘.\"\n",
    "res_format = \"{contents}\"\n",
    "\n",
    "with open(naverpedia_class_path, \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "naverpedia= []\n",
    "for i in range(len(json_data)):\n",
    "    ins = ins_format.format_map(json_data[i])\n",
    "    res = json_data[i][\"contents\"].strip()\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '컴퓨터 과목 내 인터넷 중독 [Internet Addiction]을 주제로 수업 자료를 작성해줘.', 'output': '## 예시\\n인터넷 중독 증상에 대하여 다음과 같은 인터넷 사이트를 통하여 진단할 수 있습니다.https://www.iapc.or.kr/dia/survey/addDiaSurveyNew.do?dia_type_cd=IABO만약 중독 증상을 보인다면 전문가와 상담하여 치료를 받는 것이 좋습니다. 중독 증상에 대하여 교육이나 상담을 할 수 있는 곳은 다음과 같습니다.스마트 쉼 센터 1599-0075## 설명\\n인터넷에 중독되면 인터넷을 사용하지 않을 때 불안해지며 습관적으로 인터넷을 사용하게 됩니다. 또한 건강을 해치고 공부에 신경을 덜 쓰게 되며 친구 및 가족 관계에 소홀해지게 됩니다.'}\n"
     ]
    }
   ],
   "source": [
    "print(naverpedia[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAVERPEDIA_manual하게 선별 필요 부분\n",
    "\n",
    "+ 어린이백과_국어, 영어\n",
    "+ 어린이백과_예체능 \n",
    "+ 어린이백과_시사/논술\n",
    "+ 어린이백과_문학 탐구\n",
    "+ 어린이백과_인물 탐구\n",
    "+ 어린이백과_지식e\n",
    "+ 어린이백과_천재학습백과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "naverpedia_path = \"../data/web_crawled/naverpedia.json\"\n",
    "with open(naverpedia_path, \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "def get_dictionary_by_category(json, category):\n",
    "    list = []\n",
    "    for item in json:\n",
    "        if \"category\" in item and item[\"category\"] ==category:\n",
    "            list.append(item)\n",
    "    return list\n",
    "\n",
    "#format for 어린이백과 시사/논술 \n",
    "ins_format2 = \"{title} 주제에 관련해서 실생활에서 볼 수 있는 사례를 들면서 설명하려고 해. {title}에 관한 사례를 들고 구체적으로 설명해줘.\"\n",
    "res_format2 = \"{contents}\"\n",
    "kidspedia_essay = get_dictionary_by_category(json_data, \"어린이백과_시사/논술\")\n",
    "\n",
    "for i in range(len(kidspedia_essay)):\n",
    "    ins = ins_format2.format_map(kidspedia_essay[i])\n",
    "    res = res_format2.format_map(kidspedia_essay[i])\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})\n",
    "\n",
    "#format for 어린이백과 국어\n",
    "ins_format3 = \"국어사전을 작성하려고 하는데 {title} 이라는 말의 뜻이나 실생활에서 사용하는 사례를 설명해줘.\"\n",
    "res_format3 = \"{contents}\"\n",
    "kidspedia_korean = get_dictionary_by_category(json_data, \"어린이백과_국어\")\n",
    "\n",
    "for i in range(len(kidspedia_korean)):\n",
    "    ins = ins_format3.format_map(kidspedia_korean[i])\n",
    "    res = res_format3.format_map(kidspedia_korean[i])\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})\n",
    "\n",
    "#format for 어린이백과 영어\n",
    "ins_format4 = \"{title} 주제로 영어 수업자료를 만들고 있어. 실 사례를 포함해줘.\"\n",
    "res_format4 = \"{contents}\"\n",
    "kidspedia_english = get_dictionary_by_category(json_data, \"어린이백과_영어\")\n",
    "\n",
    "for i in range(len(kidspedia_english)):\n",
    "    ins = ins_format4.format_map(kidspedia_english[i])\n",
    "    res = res_format4.format_map(kidspedia_english[i])\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})\n",
    "\n",
    "#format for 어린이백과 문학탐구\n",
    "ins_format5 = \"{title}를 주제로 어린이한테 교훈을 줄 수 있는 우화를 만들어줘.\"\n",
    "res_format5 = \"{contents}\"\n",
    "kidspedia_story = get_dictionary_by_category(json_data, \"어린이백과_문학탐구\")\n",
    "\n",
    "for i in range(len(kidspedia_story)):\n",
    "    ins = ins_format5.format_map(kidspedia_story[i])\n",
    "    res = res_format5.format_map(kidspedia_story[i])\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})\n",
    "\n",
    "#format for 어린이백과 인물탐구\n",
    "ins_format6 = \"{title} 인물의 생애와 업적을 소개하는 글을 작성해줘.\"\n",
    "res_format6 = \"{contents}\"\n",
    "kidspedia_celebrity = get_dictionary_by_category(json_data, \"어린이백과_인물탐구\")\n",
    "\n",
    "for i in range(len(kidspedia_celebrity)):\n",
    "    ins = ins_format6.format_map(kidspedia_celebrity[i])\n",
    "    res = res_format6.format_map(kidspedia_celebrity[i])\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})\n",
    "\n",
    "#format for 어린이백과 지식e\n",
    "ins_format7 = \"{title}을 주제로 수업을 진행하려는데 {title}에 대해 학생들이 흥미를 느끼도록 수업 자료를 작성해줘.\"\n",
    "res_format7 = \"{contents}\"\n",
    "kidspedia_knowledge = get_dictionary_by_category(json_data, \"어린이백과_지식e\")\n",
    "\n",
    "for i in range(len(kidspedia_knowledge)):\n",
    "    ins = ins_format7.format_map(kidspedia_knowledge[i])\n",
    "    res = res_format7.format_map(kidspedia_knowledge[i])\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})\n",
    "\n",
    "#format for 어린이백과 천재학습백과\n",
    "ins_format8 = \"{title}을 주제로 수업을 진행하는데 {title}에 관한 자료를 작성해줘.\"\n",
    "res_format8 = \"{contents}\"\n",
    "kidspedia_genius = get_dictionary_by_category(json_data, \"어린이백과_천재학습백과\")\n",
    "\n",
    "for i in range(len(kidspedia_genius)):\n",
    "    ins = ins_format8.format_map(kidspedia_genius[i])\n",
    "    res = res_format8.format_map(kidspedia_genius[i])\n",
    "    naverpedia.append({\"instruction\":ins, \"output\":res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '양파는 어떤 식물 부위인가요? 그리고 고구마는 뿌리인가요?', 'output': '양파는 잎이 아닌 식물의 줄기 부분입니다. 고구마는 식물의 뿌리 부분입니다. \\n\\n식물의 부위의 구분에 대해 궁금해하는 분이라면 분명 이 질문에 대한 답을 찾고 있을 것입니다. 양파는 잎이 아닌 줄기 부분입니다. 고구마는 다른 질문과 답변에서 언급된 것과 같이 뿌리 부분입니다. 따라서, 양파는 식물의 줄기 부분이 되고, 고구마는 식물의 뿌리 부분입니다.\\n\\n 덧붙이는 답변: 고구마 줄기도 볶아먹을 수 있나요? \\n\\n고구마 줄기도 식용으로 볶아먹을 수 있습니다. 하지만 줄기 뿐만 아니라, 잎, 씨, 뿌리까지 모든 부위가 식용으로 활용되기도 합니다. 다만, 한국에서는 일반적으로 뿌리 부분인 고구마를 주로 먹습니다.', 'url': 'https://kin.naver.com/qna/detail.naver?d1id=11&dirId=1116&docId=55320268'}\n",
      "{'source': 'korquad-chat', 'text': '<sys>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\\n<usr> 바그너가 1839년에 파우스트를 소재로 한 교향곡 작곡을 시작했다는데, 왜 이 소재에 마음이 끌렸을까요?\\n<bot> 바그너는 파우스트의 메피스토펠레스를 만나는 파우스트의 심경에 공감했기 때문입니다. 또한 바그너는 파리에서 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았고, 이것이 이 작품에 조금 영향을 끼쳤다고 합니다.\\n<usr> 작곡을 시작한 이후 작업은 어떻게 진행됐나요?\\n<bot> 작곡을 시작한 1839년부터 40년에 걸쳐 파리에서 작업을 시작했지만, 1악장을 쓴 뒤 중단하게 됐습니다. 그리고 이 간 동안 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 바쁜 시간을 보냈는데 이런 바쁜 생활이 이 곡을 잊게 한 것이 아닐까 추측되고 있습니다.\\n<usr> 그렇다면 이 작품이 연주되지 않은 이유는 무엇인가요?\\n<bot> 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였지만, 실제로는 이루어지지 않았습니다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고, 재연도 이루어졌지만, 이후에는 그대로 방치되고 말았습니다.'}\n"
     ]
    }
   ],
   "source": [
    "# print(koalpaca_v1_0[0])\n",
    "print(koalpaca_v1_1[0])\n",
    "# print(kochatgpt[0])\n",
    "print(korquad[0])\n",
    "# print(oig[0])\n",
    "# print(sharegpt[0])\n",
    "# print(kullm[-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unifying except for Korquad dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21155 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21155/21155 [00:00<00:00, 124678.58it/s]\n",
      "100%|██████████| 2711/2711 [00:00<00:00, 113254.56it/s]\n",
      "100%|██████████| 5913/5913 [00:00<00:00, 153101.55it/s]\n",
      "100%|██████████| 878/878 [00:00<00:00, 142559.57it/s]\n",
      "100%|██████████| 310/310 [00:00<00:00, 111925.13it/s]\n",
      "100%|██████████| 26782/26782 [00:00<00:00, 136704.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57749"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def to_dialog(data, inst_key, out_key, domain, preprossing=True):\n",
    "    dialog = []\n",
    "    for sample in tqdm(data, total=len(data)):\n",
    "        if preprossing:\n",
    "            inst = re.sub(r\"\\?(\\w)\", r\"?\\n\\1\", sample[inst_key])\n",
    "            output = re.sub(r\"[.](\\d+)[.]\", r\".\\n\\1.\", sample[out_key])\n",
    "        \n",
    "        dialog.append(\n",
    "            [{\"from\": \"human\", \"value\": inst},\n",
    "             {\"from\": \"bot\", \"value\": output, \"domain\":domain}]\n",
    "        )\n",
    "    return dialog\n",
    "\n",
    "print(\"Unifying except for Korquad dataset\")\n",
    "unified_data = []\n",
    "# koalpacav1.1\n",
    "unified_data.extend(to_dialog(koalpaca_v1_1, \"instruction\", \"output\", \"general\"))\n",
    "# Naverpedia\n",
    "unified_data.extend(to_dialog(naverpedia, \"instruction\", \"output\", \"education\"))\n",
    "# GSM8K\n",
    "unified_data.extend(to_dialog(gsm8k_solve, \"instruction\", \"output\", \"education\"))\n",
    "unified_data.extend(to_dialog(gsm8k_gen, \"instruction\", \"output\", \"education\"))\n",
    "# Sci 6 grade\n",
    "unified_data.extend(to_dialog(sci_six_gen, \"instruction\", \"output\", \"education\"))\n",
    "unified_data.extend(to_dialog(sci_six_res, \"instruction\", \"output\", \"education\"))\n",
    "\n",
    "# kochatgpt\n",
    "# unified_data.extend(to_dialog(kochatgpt, \"prompt\", \"completion\", \"general\"))\n",
    "# OIG\n",
    "# unified_data.extend(to_dialog(oig, \"user_translated\", \"chip2_translated\", \"general\"))\n",
    "    \n",
    "# KULLM-v2\n",
    "\"\"\"\n",
    "processed_kullm = []\n",
    "for sample in tqdm(kullm, total=len(kullm)):\n",
    "    if sample[\"input\"]:\n",
    "        inst = sample[\"instruction\"].strip()+\"\\n\\n\"+sample[\"input\"].strip()\n",
    "    else:\n",
    "        inst = sample[\"instruction\"].strip()\n",
    "        \n",
    "    if len(inst) <= 15:\n",
    "        continue\n",
    "    \n",
    "    output = re.sub(r\"[.](\\d+)[.]\", r\".\\r\\n\\1.\", sample[\"output\"])\n",
    "        \n",
    "    processed_kullm.append(\n",
    "        [{\"from\": \"human\", \"value\": inst},\n",
    "         {\"from\": \"bot\", \"value\": output}]\n",
    "    )\n",
    "print(len(processed_kullm))\n",
    "unified_data.extend(processed_kullm)\n",
    "\"\"\"\n",
    "\n",
    "# unified_data.extend(koalpaca_v1_0)\n",
    "len(unified_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Korquard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66977"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sample in korquad:#, total=len(korquad)):\n",
    "    try:\n",
    "        turns = sample[\"text\"].split(\"\\n\")\n",
    "        context = turns[0].split(\">\")[1].strip()\n",
    "        dialog = []\n",
    "        for turn in turns[1:]:\n",
    "            splited = turn.split(\">\")\n",
    "            role = splited[0][1:]\n",
    "            text = splited[1].strip()\n",
    "            dialog.append({\"role\": role, \"text\": text})\n",
    "            \n",
    "        assert dialog[0][\"role\"]==\"usr\" and len(dialog)%2==0\n",
    "        \n",
    "        inst_res = []\n",
    "        for i in range(0, len(dialog), 2):\n",
    "            user = dialog[i][\"text\"]\n",
    "            if i==0:\n",
    "                user = context.strip()+\"\\n\\n\"+user.strip()\n",
    "            bot = dialog[i+1][\"text\"]\n",
    "        \n",
    "            inst_res.extend(\n",
    "                [{\"from\": \"human\", \"value\": user},\n",
    "                 {\"from\": \"bot\", \"value\": bot,}]\n",
    "            )\n",
    "        inst_res[1][\"domain\"] = \"general\"\n",
    "                \n",
    "        unified_data.append(inst_res)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "len(unified_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Hub Book summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180001/180001 [00:06<00:00, 27881.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "json_files = glob(\"../data/AIhub_book_summary/*.json\")\n",
    "\n",
    "ins1_format = \"다음 문단은 \\'{kdc_label}\\'로 분류된 문서의 일부분이다.\\n\\n{passage1}\\n\\n이 문단에 이어질 한 문장을 작성해줘\"\n",
    "res1_format = \"\\\"{passage2}\\\"가 될 수 있겠습니다.\"\n",
    "ins2_format = \"완성된 문단을 간단히 요약하고 해당 문서의 제목을 지어줘\"\n",
    "res2_format = \"이 문단은 다음과 같이 요약될 수 있습니다.\\r\\n- 요약: {summary}\\r\\n\\r\\n- {kdc_label} {doc_type} 제목 제안: \\\"{doc_name}\\\"\"\n",
    "\n",
    "target_kdc = [\"보건의료\", \"체육\", \"보육·가족및여성\", \"한국문학\", \"한국어\", \"문학\", \"문화재\", \"역사\", \"음악\", \"심리학\"]\n",
    "book_summary = []\n",
    "kdcs = []\n",
    "for path in tqdm(json_files):\n",
    "    with open(path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "    data = json_data[\"metadata\"]\n",
    "    kdcs.append(data[\"kdc_label\"])\n",
    "        \n",
    "    if \"교육\" in data[\"kdc_label\"] or data[\"kdc_label\"] in target_kdc:\n",
    "        splited_passage = json_data[\"passage\"].split(\". \")\n",
    "        data[\"passage1\"] = \". \".join(splited_passage[:-1])+\".\"\n",
    "        data[\"passage2\"] = splited_passage[-1]\n",
    "        data[\"summary\"] = json_data[\"summary\"]\n",
    "        ins1 = ins1_format.format_map(data)\n",
    "        res1 = res1_format.format_map(data)\n",
    "        ins2 = ins2_format.format_map(data)\n",
    "        res2 = res2_format.format_map(data)\n",
    "        book_summary.append([\n",
    "            {\"from\":\"human\", \"value\":ins1},\n",
    "            {\"from\":\"bot\", \"value\":res1, \"domain\":\"general\"},\n",
    "            {\"from\":\"human\", \"value\":ins2},\n",
    "            {\"from\":\"bot\", \"value\":res2},\n",
    "        ])\n",
    "    #     data[\"passage\"] = json_data[\"passage\"]\n",
    "    #     data[\"summary\"] = json_data[\"summary\"]\n",
    "    #     ins = ins_format.format_map(data)\n",
    "    #     res = res_format.format_map(data)\n",
    "    #     kdcs.append(data[\"kdc_label\"])\n",
    "    #     book_summary.append({\"instruction\":ins, \"output\":res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_data.extend(book_summary)\n",
    "len(unified_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI hub 주제별 일상 대화 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/AIhub_chitchat/KAKAO_1648_13.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98651"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "chitchat_list = glob(\"../data/AIhub_chitchat/*.json\")\n",
    "chitchat_data = []\n",
    "\n",
    "for path in chitchat_list:\n",
    "    try:\n",
    "        with open(path, \"r\") as fin:\n",
    "            chitchat_data.append(json.load(fin))\n",
    "    except Exception:\n",
    "        print(path)\n",
    "        continue\n",
    "\n",
    "len(chitchat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70613\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "dialogs = []\n",
    "for data in chitchat_data:\n",
    "    data = data[\"info\"][0]\n",
    "    domain = data[\"annotations\"][\"speaker_type\"]\n",
    "    if data[\"annotations\"][\"speaker_type\"]!=\"1:1\":\n",
    "        continue\n",
    "    \n",
    "    data = data[\"annotations\"]\n",
    "    lines = data[\"lines\"]\n",
    "    \n",
    "    if len(lines) < 2 or not data[\"lines\"][0][\"norm_text\"]:\n",
    "        continue\n",
    "    \n",
    "    if len(set([line[\"speaker\"][\"id\"] for line in lines]))!=2:\n",
    "        continue\n",
    "       \n",
    "    user_info = lines[0][\"speaker\"]\n",
    "    u_id = user_info[\"id\"]\n",
    "    u_gender = user_info[\"sex\"]\n",
    "    u_age = user_info[\"age\"]\n",
    "    \n",
    "    prev_id = u_id\n",
    "    dialog = []\n",
    "    user = []\n",
    "    bot = []\n",
    "    for i in range(len(lines)):\n",
    "        cur_id = lines[i][\"speaker\"][\"id\"]\n",
    "        if prev_id!=cur_id and prev_id!=u_id:\n",
    "            response = \" \".join(bot).strip()\n",
    "            response = re.sub(\"키키\", \"ㅋㅋ\", response)\n",
    "            dialog.extend(\n",
    "                [{\"from\": \"human\", \"value\": \" \".join(user).strip()},\n",
    "                 {\"persona\": {\"age\": a_age, \"gender\": a_gender, \"domain\": \"일상 대화\"}, \"from\": \"bot\", \"value\": response}]\n",
    "            )\n",
    "            user = []\n",
    "            bot = []\n",
    "\n",
    "        if cur_id!=u_id:\n",
    "            a_gender = lines[i][\"speaker\"][\"sex\"]\n",
    "            a_age = lines[i][\"speaker\"][\"age\"]\n",
    "            bot.append(lines[i][\"norm_text\"])\n",
    "        else:\n",
    "            user.append(lines[i][\"norm_text\"])\n",
    "            \n",
    "        prev_id = cur_id\n",
    "    \n",
    "    if dialog:\n",
    "        dialogs.append(dialog.copy())\n",
    "    \n",
    "print(len(dialogs))\n",
    "\n",
    "unified_data.extend(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/unified_instruction_clean.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(unified_data, f, ensure_ascii=False) # ensure_ascii로 한글이 깨지지 않게 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
